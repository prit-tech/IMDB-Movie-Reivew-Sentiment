{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis_IMDB_Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.14"
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prit-tech/IMDB-Movie-Reivew-Sentiment/blob/master/Sentiment_Analysis_IMDB_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xT7MKZuMRaCg"
      },
      "source": [
        "# Sentiment Classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zSsEdNtkGUf",
        "colab_type": "text"
      },
      "source": [
        "**Problem Description:**\n",
        "Generate Word Embedding and retrieve outputs of each layer with Keras based\n",
        "on the Classification task.\n",
        "Word embedding are a type of word representation that allows words with\n",
        "similar meaning to have a similar representation.\n",
        "It is a distributed representation for the text that is perhaps one of the key\n",
        "breakthroughs for the impressive performance of deep learning methods on\n",
        "challenging natural language processing problems.\n",
        "We will use the IMDb dataset to learn word embedding as we train our dataset.\n",
        "This dataset contains 25,000 movie reviews from IMDB, labeled with a sentiment\n",
        "(positive or negative).\n",
        "\n",
        "**Data Description:**\n",
        "The Dataset of 25,000 movie reviews from IMDB, labeled by sentiment\n",
        "(positive/negative). Reviews have been preprocessed, and each review is encoded\n",
        "as a sequence of word indexes (integers). For convenience, the words are indexed\n",
        "by their frequency in the dataset, meaning the for that has index 1 is the most\n",
        "frequent word. Use the first 20 words from each review to speed up training,\n",
        "using a max vocab size of 10,000.\n",
        "As a convention, \"0\" does not stand for a specific word, but instead is used to\n",
        "encode any unknown word.\n",
        "\n",
        "**Steps and tasks:**\n",
        "1. Import test and train data (5 points)\n",
        "2. Import the labels (train and test) (5 points)\n",
        "3. Get the word index and then Create a key-value pair for word and word_id\n",
        "(15 points)\n",
        "4. Build a Sequential Model using Keras for the Sentiment Classification task\n",
        "(15 points)\n",
        "5. Report the Accuracy of the model (5 points)\n",
        "6. Retrieve the output of each layer in Keras for a given single test sample\n",
        "from the trained model you built (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B68Bo2xNS7Zo",
        "colab_type": "code",
        "outputId": "4d8e307e-7848-4bc1-ebee-c7158012297b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDElTz0gTA0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Colab/Deep Learning/Natural Language Processing/Project/')\n",
        "path = '.'\n",
        "glove_dir = '/content/drive/My Drive/Colab/Deep Learning/Natural Language Processing/Project/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOnOZt9NSkWs",
        "colab_type": "text"
      },
      "source": [
        "## Importing all the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1a9RtcZSitY",
        "colab_type": "code",
        "outputId": "348508ce-2779-45da-c11c-0926afdb1c03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.layers import Activation, Dense\n",
        "from keras.layers import Dropout, Flatten\n",
        "from keras import regularizers\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wq4RCyyPSYRp"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NGCtiXUhSWss",
        "colab": {}
      },
      "source": [
        "from keras.datasets import imdb\n",
        "\n",
        "vocab_size = 10000 #vocab size\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size) # vocab_size is no.of words to consider from the dataset, ordering based on frequency."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP4ns5SCVGeY",
        "colab_type": "text"
      },
      "source": [
        "### Printing the first training record"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iJ2uYwxUVEf",
        "colab_type": "code",
        "outputId": "b11fc3b7-b24c-45e1-c40d-b361f0416bff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(x_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHyr-K1hZbLM",
        "colab_type": "text"
      },
      "source": [
        "### The corresponding label:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPQuH1c2UzNQ",
        "colab_type": "code",
        "outputId": "bf3a2f16-ec58-4614-9a44-bc16421a0e86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(\"Label: \", y_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Label: ', 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peO2Au6sZ103",
        "colab_type": "text"
      },
      "source": [
        "### Get the word index and then Create a key-value pair for word and word_id"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQmpC6S0mjpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index = imdb.get_word_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_s9pPfCaXMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_word = {k:v for k,v in word_index.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvTgKTNhaXXe",
        "colab_type": "code",
        "outputId": "0bb761c3-5e57-45da-e761-5c2330ef70cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "word_index = imdb.get_word_index() # get {word : index}\n",
        "index_word = {v : k for k,v in word_index.items()} # get {index : word}\n",
        "\n",
        "index = 0\n",
        "print(\" \".join([index_word[idx] for idx in x_train[index]]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZuEfJb9b14K",
        "colab_type": "text"
      },
      "source": [
        "Displaying the sentiment(label) of above review:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTu4TCQcaXeA",
        "colab_type": "code",
        "outputId": "ec73e599-92ed-44a6-c2a0-08a472953a1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(\"Positve\" if y_train[index]==1 else \"Negetive\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positve\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dg7WCcHaXiU",
        "colab_type": "code",
        "outputId": "dc4d9866-ad97-4b43-d4e3-69487eb6fdea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(\"Total %s unique tokens.\" % len(word_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total 88584 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7ORh5KH5cP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "vocab_size = 10000 #vocab size\n",
        "maxlen = 300  #number of word used from each review"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMEsHYrWxdtk",
        "colab_type": "text"
      },
      "source": [
        "## Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0g381XzeCyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load dataset as a list of ints\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
        "#make all sequences of the same length \n",
        "x_train = pad_sequences(x_train, maxlen=maxlen, padding='post')\n",
        "x_test =  pad_sequences(x_test, maxlen=maxlen, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy6n-uM2eCy2",
        "colab_type": "code",
        "outputId": "b669ce91-d804-4c2a-dc35-55ee71c936f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "x_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   1,   14,   22, ...,    0,    0,    0],\n",
              "       [   1,  194, 1153, ...,    0,    0,    0],\n",
              "       [   1,   14,   47, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [   1,   11,    6, ...,    0,    0,    0],\n",
              "       [   1, 1446, 7079, ...,    0,    0,    0],\n",
              "       [   1,   17,    6, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZhMAgaNeCy5",
        "colab_type": "code",
        "outputId": "dc360a45-0e15-4b86-cbd9-e50ba2ad5043",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "x_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   1,  591,  202, ...,    0,    0,    0],\n",
              "       [   1,   14,   22, ...,    0,    0,    0],\n",
              "       [1239, 5189,  137, ...,    9,   57,  975],\n",
              "       ...,\n",
              "       [   1,   13, 1408, ...,    0,    0,    0],\n",
              "       [   1,   11,  119, ...,    0,    0,    0],\n",
              "       [   1,    6,   52, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpl9BsyPc8mx",
        "colab_type": "code",
        "outputId": "be0b6017-e2c0-4711-b54f-0eb3a4756a2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "y_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EYK5EYBc-Nk",
        "colab_type": "code",
        "outputId": "cfb4232d-af87-4e46-ae4c-6ee3bd89c970",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "y_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sutq9-PXnonz",
        "colab_type": "code",
        "outputId": "dedc9aa3-c294-4218-99bb-656de6eae0cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "print('x_train Shape : ', x_train.shape)\n",
        "print('x_test Shape  : ', x_test.shape)\n",
        "print('y_train Shape : ', y_train.shape)\n",
        "print('y_test Shape  : ', y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('x_train Shape : ', (25000, 300))\n",
            "('x_test Shape  : ', (25000, 300))\n",
            "('y_train Shape : ', (25000,))\n",
            "('y_test Shape  : ', (25000,))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dybtUgUReCy8",
        "colab_type": "text"
      },
      "source": [
        "## Build Keras Embedding Layer Model\n",
        "We can think of the Embedding layer as a dicionary that maps a index assigned to a word to a word vector. This layer is very flexible and can be used in a few ways:\n",
        "\n",
        "* The embedding layer can be used at the start of a larger deep learning model. \n",
        "* Also we could load pre-train word embeddings into the embedding layer when we create our model.\n",
        "* Use the embedding layer to train our own word2vec models.\n",
        "\n",
        "The keras embedding layer doesn't require us to onehot encode our words, instead we have to give each word a unqiue intger number as an id. For the imdb dataset we've loaded this has already been done, but if this wasn't the case we could use sklearn [LabelEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yx1fvtoOdnXK",
        "colab_type": "text"
      },
      "source": [
        "#### Here I am using pretrained GloVe Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDqw7cSwwu7I",
        "colab_type": "code",
        "outputId": "a9930dfa-482c-40d9-fc5f-23627225d17b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "embeddings_index = {}\n",
        "\n",
        "f = open(os.path.join(glove_dir, \"glove.6B.50d.txt\"))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype=\"float32\")\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print(\"found %s word vectors.\" % len (embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfvk9Fqgfj3T",
        "colab_type": "text"
      },
      "source": [
        "The entire GloVe word embedding file is loaded into memory as a dictionary of word to embedding array embeddings_index = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm-DD18Of2fR",
        "colab_type": "text"
      },
      "source": [
        "Next, we need an embedding matrix that can be loaded into an Embedding layer. The matrix shape must be (max_words, embedding_dim), which is has a shape of a 10000 x 50 matrix. GloVe is 50 x 400000."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBq0D50Cerr7",
        "colab_type": "code",
        "outputId": "0091fbe8-8d20-4892-aca0-57893a012b0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "print(embeddings_index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHgxBVY0gMf_",
        "colab_type": "text"
      },
      "source": [
        "### Preparing the GloVe word embeddings matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOB5i7esyplV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 50 # GloVe contains 50-dimensional embedding vectors for 400000 words\n",
        "maxlen = 300 \n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim)) # embedding_matrix.shape (10000, 50)\n",
        "for word, i in word_index.items():\n",
        "    if i < vocab_size:\n",
        "        embedding_vector = embeddings_index.get(word) # embedding_vector.shape (50,)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector # Words not found in the mebedding index will all be zeros"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHJWKifM817e",
        "colab_type": "code",
        "outputId": "23bdc705-a664-484c-ab24-e88db16f6cf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "print(embedding_matrix)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.41800001  0.24968    -0.41242    ... -0.18411    -0.11514\n",
            "  -0.78580999]\n",
            " [ 0.26818001  0.14346001 -0.27877    ... -0.63209999 -0.25027999\n",
            "  -0.38097   ]\n",
            " ...\n",
            " [-0.47567001  0.64363998 -0.32692    ... -0.20565    -0.093098\n",
            "  -0.46967   ]\n",
            " [ 0.26205999 -0.50996    -0.78754997 ...  0.43805     0.32886001\n",
            "   0.26629999]\n",
            " [-0.063412    0.72070003 -0.46972999 ... -0.81309003  0.2098\n",
            "   0.41644001]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdkdRqqahmMf",
        "colab_type": "text"
      },
      "source": [
        "## Build a Sequential Model using Keras for the Sentiment Classification task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvcrbsyGEynp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inp = Input(shape=(maxlen,))\n",
        "x = Embedding(vocab_size, embedding_dim, weights=[embedding_matrix])(inp)\n",
        "x = Bidirectional(LSTM(embedding_dim, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dense(300, activation=\"relu\")(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(1, activation=\"sigmoid\")(x)\n",
        "model = Model(inputs=inp, outputs=x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0ynEgRHi-VH",
        "colab_type": "code",
        "outputId": "80d2ab62-ee4d-469f-99be-d0cb4a1f80fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 300, 50)           500000    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 300, 100)          40400     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 300)               30300     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 301       \n",
            "=================================================================\n",
            "Total params: 571,001\n",
            "Trainable params: 571,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdwfA-wSh98i",
        "colab_type": "text"
      },
      "source": [
        "### Compiling the model and setting the calback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-x9c6P9qhEiO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks = [EarlyStopping(monitor = 'val_loss', patience= 5)]\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBvA4JVfihwd",
        "colab_type": "text"
      },
      "source": [
        "### Training the Model and Reporting the Accuracy of the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95_LPf4dTMWl",
        "colab_type": "code",
        "outputId": "32e9bc52-81ba-4c76-b66c-0e79322934d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "history = model.fit(x_train, y_train, validation_data=(x_test, y_test),\n",
        "          epochs=10, batch_size=64, callbacks = callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 220s 9ms/step - loss: 0.0584 - accuracy: 0.9804 - val_loss: 0.4477 - val_accuracy: 0.8760\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 220s 9ms/step - loss: 0.0446 - accuracy: 0.9848 - val_loss: 0.4687 - val_accuracy: 0.8771\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 220s 9ms/step - loss: 0.0349 - accuracy: 0.9888 - val_loss: 0.5079 - val_accuracy: 0.8756\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 220s 9ms/step - loss: 0.0322 - accuracy: 0.9886 - val_loss: 0.5827 - val_accuracy: 0.8714\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 219s 9ms/step - loss: 0.0258 - accuracy: 0.9910 - val_loss: 0.6699 - val_accuracy: 0.8551\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 219s 9ms/step - loss: 0.0254 - accuracy: 0.9914 - val_loss: 0.6100 - val_accuracy: 0.8728\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLlkREc7Ija9",
        "colab_type": "text"
      },
      "source": [
        "<b>Comment:</b> Here I have set a callback fucntion which will stop the iteration if accuracy will not be increasing futher so it stops at 6 epocs.\n",
        "Train accuracy is 99 and validation accuray is 87 which is a sign of that the model will perform well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0663jegCJ6If",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkBAZrK3QFh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Saving model\n",
        "model.save('IMDB_model_GL.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLZ3s8ntZ3t1",
        "colab_type": "code",
        "outputId": "0bffdb0f-df55-4392-9d42-802e3fe3f80d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Next, comparing how the model performs on the test dataset:\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 69s 3ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPTQzB-Xn5n4",
        "colab_type": "code",
        "outputId": "a53f8bba-0341-41b8-dee9-fe193c8ceea5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Test loss:', 0.6099941605952383)\n",
            "('Test accuracy:', 0.8728399872779846)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_ojZndqqA4U",
        "colab_type": "text"
      },
      "source": [
        "#### Making predicitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ruj8gX4IqPjY",
        "colab_type": "code",
        "outputId": "2550c935-3aee-4a3f-e88f-c80e2dbae7ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%%time\n",
        "mode_predict=model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 5s, sys: 502 ms, total: 1min 6s\n",
            "Wall time: 1min 4s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3FIeEPPqFyB",
        "colab_type": "text"
      },
      "source": [
        "#### Changing the shape of y_predict to 1-Dimensional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tB6w1t2Y6a5",
        "colab_type": "code",
        "outputId": "8d7452b4-8431-4f52-d000-e316eb0175f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "y_predict=mode_predict.ravel()\n",
        "y_predict=(y_predict>0.5)\n",
        "y_predict[0:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False,  True, False,  True,  True,  True,  True, False,  True,\n",
              "        True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISzfN0n6EoHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted = model.predict(x_test)\n",
        "predicted_y = predicted.round().ravel().astype('int32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYb2oQjCZx5J",
        "colab_type": "code",
        "outputId": "4fe3c14b-c79d-4c8c-a0b2-2b08cef85f2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "predicted_df = pd.DataFrame( { \"Y Actual\":y_test, \"Y Predicted\": predicted_y } )\n",
        "predicted_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Y Actual  Y Predicted\n",
              "0         0            0\n",
              "1         1            1\n",
              "2         1            0\n",
              "3         0            1\n",
              "4         1            1"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Y Actual</th>\n",
              "      <th>Y Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqdjK0CSOSfp",
        "colab_type": "text"
      },
      "source": [
        "<b>Comment: </b> Above I have displayed the actual and predicted label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAUASjF3qPVY",
        "colab_type": "text"
      },
      "source": [
        "#### Classification report for performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rVL_BP_qTQE",
        "colab_type": "code",
        "outputId": "deca8855-53f9-4558-fa62-f90c9bc18790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "classsificationReport = classification_report(y_test,y_predict, target_names=['Negative', 'Positive'])\n",
        "print(classsificationReport)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.86      0.89      0.87     12500\n",
            "    Positive       0.89      0.86      0.87     12500\n",
            "\n",
            "   micro avg       0.87      0.87      0.87     25000\n",
            "   macro avg       0.87      0.87      0.87     25000\n",
            "weighted avg       0.87      0.87      0.87     25000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqerFPOPqWoz",
        "colab_type": "code",
        "outputId": "9fe3f254-1677-4218-cd56-de01e7c1f8b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "confusionMatrix = confusion_matrix(y_test,y_predict)\n",
        "confusionMatrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[11110,  1390],\n",
              "       [ 1789, 10711]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy3ESWmWS_D9",
        "colab_type": "code",
        "outputId": "77ccdc17-e18b-42ee-f389-23b9f44ea3ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Igq8Qm8GeCzG",
        "colab_type": "text"
      },
      "source": [
        "## Retrive the output of each layer in keras for a given single test sample from the trained model you built"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50qhoYWXD5l-",
        "colab_type": "text"
      },
      "source": [
        "##### Here I am taking two test samples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIAbxZl0DtX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sample_1 = 20\n",
        "test_sample_2 = 113"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q38wo-GVEzs0",
        "colab_type": "text"
      },
      "source": [
        "#### Here displaying the output of each layers for a given test sample test_sample_1 :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT02ge4trtQn",
        "colab_type": "code",
        "outputId": "5b81dd21-dd12-4d73-9b7f-faa066bb3b9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "inp = model.input                                           \n",
        "outputs = [layer.output for layer in model.layers]      \n",
        "functors = [K.function([inp], [out]) for out in outputs]    \n",
        "test = x_test[test_sample_1][np.newaxis,...]\n",
        "layer_outs = [func([test]) for func in functors]\n",
        "print(layer_outs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[array([[1.000e+00, 1.400e+01, 2.200e+01, 1.600e+01, 3.100e+01, 1.500e+01,\n",
            "        1.300e+01, 2.800e+01, 4.465e+03, 8.000e+00, 6.700e+01, 1.800e+01,\n",
            "        4.900e+01, 5.800e+01, 1.300e+01, 1.600e+01, 1.264e+03, 8.000e+00,\n",
            "        1.690e+02, 1.200e+01, 4.700e+01, 7.700e+01, 2.850e+02, 6.658e+03,\n",
            "        4.000e+00, 4.870e+02, 7.000e+00, 1.400e+01, 2.200e+01, 4.700e+01,\n",
            "        7.700e+01, 3.800e+01, 8.625e+03, 2.882e+03, 5.000e+00, 2.000e+00,\n",
            "        2.300e+02, 7.240e+02, 5.100e+01, 9.000e+00, 1.100e+02, 3.400e+01,\n",
            "        4.000e+00, 3.110e+02, 1.300e+01, 2.580e+02, 1.200e+01, 1.139e+03,\n",
            "        1.500e+01, 3.800e+01, 1.110e+02, 8.400e+01, 1.490e+02, 8.000e+01,\n",
            "        2.400e+01, 3.320e+02, 2.000e+02, 4.900e+01, 5.500e+01, 6.740e+02,\n",
            "        4.110e+02, 2.100e+01, 8.490e+02, 4.800e+01, 2.400e+01, 4.000e+00,\n",
            "        2.000e+01, 8.000e+01, 9.700e+01, 2.810e+02, 1.100e+01, 6.000e+00,\n",
            "        2.750e+02, 9.600e+01, 5.000e+00, 9.000e+00, 5.500e+01, 5.300e+02,\n",
            "        4.000e+00, 2.200e+01, 4.700e+01, 1.110e+02, 5.370e+02, 5.000e+00,\n",
            "        1.050e+02, 9.320e+03, 2.950e+02, 1.870e+02, 1.400e+01, 3.100e+01,\n",
            "        1.090e+02, 2.000e+00, 6.000e+00, 1.320e+02, 9.370e+02, 4.700e+01,\n",
            "        2.313e+03, 3.900e+01, 4.000e+00, 1.986e+03, 6.929e+03, 1.110e+02,\n",
            "        2.000e+00, 5.000e+00, 4.130e+02, 6.000e+00, 5.500e+01, 9.760e+02,\n",
            "        1.676e+03, 1.030e+02, 3.427e+03, 4.900e+01, 5.800e+01, 1.100e+01,\n",
            "        1.172e+03, 2.000e+00, 6.590e+02, 6.000e+00, 2.000e+00, 1.100e+01,\n",
            "        4.000e+00, 1.351e+03, 1.510e+03, 5.000e+00, 1.430e+02, 6.000e+00,\n",
            "        1.193e+03, 4.710e+02, 7.000e+00, 6.870e+02, 9.000e+00, 6.260e+02,\n",
            "        6.400e+01, 8.000e+00, 1.690e+02, 2.850e+02, 9.000e+00, 2.400e+01,\n",
            "        3.300e+01, 3.200e+01, 5.100e+01, 1.200e+01, 1.860e+02, 2.000e+00,\n",
            "        6.590e+02, 3.090e+02, 1.700e+02, 5.600e+01, 4.290e+02, 4.000e+00,\n",
            "        1.931e+03, 5.513e+03, 7.000e+00, 9.260e+02, 5.000e+00, 9.930e+02,\n",
            "        2.000e+00, 1.100e+01, 6.610e+02, 8.000e+00, 9.700e+01, 7.880e+02,\n",
            "        8.900e+01, 6.740e+02, 6.000e+00, 1.601e+03, 6.810e+02, 9.000e+00,\n",
            "        5.000e+00, 1.407e+03, 1.800e+01, 6.000e+00, 3.250e+02, 7.780e+02,\n",
            "        1.700e+01, 4.000e+00, 8.900e+02, 9.000e+00, 1.100e+01, 2.800e+03,\n",
            "        4.290e+02, 2.000e+00, 7.000e+00, 4.008e+03, 5.000e+00, 3.408e+03,\n",
            "        6.710e+02, 1.000e+01, 1.000e+01, 6.000e+00, 1.703e+03, 5.600e+01,\n",
            "        8.000e+00, 6.980e+03, 5.000e+00, 9.760e+02, 7.010e+02, 5.700e+02,\n",
            "        1.299e+03, 5.000e+00, 5.050e+02, 1.400e+01, 2.200e+01, 8.000e+01,\n",
            "        5.630e+02, 2.500e+01, 2.000e+00, 1.300e+01, 2.580e+02, 4.000e+00,\n",
            "        1.770e+02, 7.000e+00, 1.400e+01, 2.000e+01, 8.000e+00, 3.000e+01,\n",
            "        1.339e+03, 5.000e+00, 9.000e+00, 2.400e+01, 6.000e+00, 2.000e+01,\n",
            "        8.000e+00, 3.000e+01, 3.714e+03, 3.210e+02, 1.400e+02, 8.510e+02,\n",
            "        1.200e+01, 6.390e+02, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00]],\n",
            "      dtype=float32)], [array([[[ 0.44701034,  0.16940914, -0.35161245, ...,  0.02739534,\n",
            "         -0.1957903 , -0.78419554],\n",
            "        [-0.05687324, -0.27258164, -0.13270004, ..., -0.4231101 ,\n",
            "          0.27917808, -0.07869627],\n",
            "        [ 0.17326477,  0.08451032,  0.6394281 , ..., -0.38761756,\n",
            "          0.01866693,  1.2855837 ],\n",
            "        ...,\n",
            "        [ 0.01541155,  0.01611452, -0.00215842, ..., -0.00337921,\n",
            "         -0.01218064, -0.01692008],\n",
            "        [ 0.01541155,  0.01611452, -0.00215842, ..., -0.00337921,\n",
            "         -0.01218064, -0.01692008],\n",
            "        [ 0.01541155,  0.01611452, -0.00215842, ..., -0.00337921,\n",
            "         -0.01218064, -0.01692008]]], dtype=float32)], [array([[[-0.02289554, -0.05007676, -0.01727924, ...,  0.06792232,\n",
            "         -0.08464837, -0.19856173],\n",
            "        [-0.068535  , -0.08967083, -0.24181096, ...,  0.0737239 ,\n",
            "         -0.13051632, -0.257659  ],\n",
            "        [-0.02560846,  0.07023446, -0.35061568, ...,  0.04098351,\n",
            "         -0.07649244, -0.20566997],\n",
            "        ...,\n",
            "        [-0.04370921, -0.05222048,  0.04624193, ..., -0.03260329,\n",
            "         -0.01740935,  0.00452425],\n",
            "        [-0.04370921, -0.05222047,  0.0462419 , ..., -0.02296646,\n",
            "         -0.0144048 ,  0.00138035],\n",
            "        [-0.04370922, -0.05222045,  0.04624188, ..., -0.01182405,\n",
            "         -0.00906729, -0.00039823]]], dtype=float32)], [array([[ 0.32216144,  0.47963098,  0.60035115,  0.05826579,  0.5638648 ,\n",
            "         0.30306086,  0.35102093,  0.3182796 ,  0.01203995,  0.69550633,\n",
            "         0.37706017,  0.13655823,  0.3650328 ,  0.3815137 ,  0.1533028 ,\n",
            "         0.16388185,  0.4110069 ,  0.20993239,  0.37731737,  0.521666  ,\n",
            "         0.19702122,  0.40018728,  0.3841583 ,  0.16568825,  0.13141589,\n",
            "         0.27562442,  0.3650857 ,  0.2606332 ,  0.11279994,  0.0658618 ,\n",
            "         0.20650156,  0.38847223,  0.29082212,  0.2556316 ,  0.09305562,\n",
            "         0.44959432,  0.60168344,  0.41206783,  0.21350735,  0.36018524,\n",
            "         0.13330288,  0.09554362,  0.32734329,  0.18007584,  0.28679425,\n",
            "         0.47143897,  0.14657256,  0.29428408,  0.3005356 ,  0.14253405,\n",
            "         0.52393883,  0.11463898,  0.21751815,  0.18462248,  0.25382435,\n",
            "         0.3045546 ,  0.50814706,  0.02621521,  0.13481584,  0.13305691,\n",
            "         0.46901643,  0.0891766 ,  0.4791561 ,  0.06997592, -0.00540906,\n",
            "         0.22083867, -0.00084765,  0.08590061,  0.3089141 ,  0.2490676 ,\n",
            "         0.2626092 ,  0.17915629,  0.14041926,  0.20506026, -0.0019977 ,\n",
            "         0.48589984,  0.5896523 ,  0.20700617, -0.01620316,  0.27791536,\n",
            "         0.00579204,  0.357106  ,  0.5564669 ,  0.4944166 ,  0.18249978,\n",
            "         0.24674188,  0.30939335,  0.26986408,  0.56348705,  0.5502825 ,\n",
            "         0.21151496,  0.05258046,  0.09054264,  0.39154294,  0.01111206,\n",
            "         0.19001622,  0.33723575,  0.24966405,  0.18160693,  0.08028533]],\n",
            "      dtype=float32)], [array([[0.6543142 , 0.        , 0.4678309 , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.7226503 , 0.        , 0.10496487,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.80539346, 0.77776045,\n",
            "        0.        , 0.        , 0.        , 0.7392917 , 0.        ,\n",
            "        0.        , 0.06972905, 0.        , 0.92213136, 0.        ,\n",
            "        1.2624618 , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.6763687 , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.8037828 , 0.75313693, 0.        ,\n",
            "        0.52162284, 0.        , 0.        , 0.11359484, 0.        ,\n",
            "        0.        , 0.7238319 , 0.        , 0.        , 0.65631694,\n",
            "        0.        , 0.4741192 , 0.73979896, 0.81473213, 0.5694695 ,\n",
            "        0.75712943, 0.05289852, 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.7421651 , 0.83163947, 0.        , 0.        , 0.63637   ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.6808256 , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.7217747 , 0.9502782 , 0.        ,\n",
            "        0.        , 0.7294102 , 0.8179417 , 0.        , 0.        ,\n",
            "        0.        , 0.78911006, 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.0988598 , 0.        ,\n",
            "        0.47487217, 0.        , 0.        , 0.8418532 , 0.        ,\n",
            "        0.        , 0.80321157, 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.9099549 , 0.        , 0.        , 0.7578877 ,\n",
            "        0.9749649 , 0.68035007, 0.        , 0.        , 0.        ,\n",
            "        0.76950824, 0.6435385 , 0.        , 0.6756536 , 0.        ,\n",
            "        0.3565842 , 0.5537271 , 0.        , 0.        , 0.6829124 ,\n",
            "        0.        , 0.        , 0.        , 0.        , 1.0509855 ,\n",
            "        0.        , 0.        , 0.4740611 , 0.        , 0.7844018 ,\n",
            "        0.8157422 , 1.0585176 , 0.        , 0.682499  , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.41384393, 0.        , 0.        ,\n",
            "        0.        , 0.05420435, 0.        , 0.        , 0.79501927,\n",
            "        0.58459085, 0.7192462 , 0.        , 0.68808943, 0.7366062 ,\n",
            "        0.        , 0.8008972 , 0.7603058 , 0.        , 0.        ,\n",
            "        0.9732673 , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.58595043, 0.        ,\n",
            "        0.        , 0.        , 0.7249135 , 0.582682  , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.6333177 , 0.        , 0.        , 0.        ,\n",
            "        0.84702843, 0.47669074, 0.        , 0.        , 0.6752565 ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.770561  , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.81485474, 0.        , 0.64058065, 0.78174216,\n",
            "        0.        , 0.        , 0.7617461 , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.82755107, 0.        , 0.        ,\n",
            "        0.80568486, 0.        , 0.        , 0.        , 0.8575809 ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.7267382 ,\n",
            "        0.6099159 , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.45891792, 0.        ,\n",
            "        0.        , 0.5996203 , 0.        , 0.7961348 , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.8309772 , 0.        ,\n",
            "        0.        , 0.        , 0.5637293 , 0.72889966, 0.77433836,\n",
            "        0.        , 0.        , 0.04498467, 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.43078363, 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.7167383 , 0.7678255 ,\n",
            "        0.        , 0.10020256, 0.7984608 , 0.        , 0.        ]],\n",
            "      dtype=float32)], [array([[0.6543142 , 0.        , 0.4678309 , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.7226503 , 0.        , 0.10496487,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.80539346, 0.77776045,\n",
            "        0.        , 0.        , 0.        , 0.7392917 , 0.        ,\n",
            "        0.        , 0.06972905, 0.        , 0.92213136, 0.        ,\n",
            "        1.2624618 , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.6763687 , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.8037828 , 0.75313693, 0.        ,\n",
            "        0.52162284, 0.        , 0.        , 0.11359484, 0.        ,\n",
            "        0.        , 0.7238319 , 0.        , 0.        , 0.65631694,\n",
            "        0.        , 0.4741192 , 0.73979896, 0.81473213, 0.5694695 ,\n",
            "        0.75712943, 0.05289852, 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.7421651 , 0.83163947, 0.        , 0.        , 0.63637   ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.6808256 , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.7217747 , 0.9502782 , 0.        ,\n",
            "        0.        , 0.7294102 , 0.8179417 , 0.        , 0.        ,\n",
            "        0.        , 0.78911006, 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.0988598 , 0.        ,\n",
            "        0.47487217, 0.        , 0.        , 0.8418532 , 0.        ,\n",
            "        0.        , 0.80321157, 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.9099549 , 0.        , 0.        , 0.7578877 ,\n",
            "        0.9749649 , 0.68035007, 0.        , 0.        , 0.        ,\n",
            "        0.76950824, 0.6435385 , 0.        , 0.6756536 , 0.        ,\n",
            "        0.3565842 , 0.5537271 , 0.        , 0.        , 0.6829124 ,\n",
            "        0.        , 0.        , 0.        , 0.        , 1.0509855 ,\n",
            "        0.        , 0.        , 0.4740611 , 0.        , 0.7844018 ,\n",
            "        0.8157422 , 1.0585176 , 0.        , 0.682499  , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.41384393, 0.        , 0.        ,\n",
            "        0.        , 0.05420435, 0.        , 0.        , 0.79501927,\n",
            "        0.58459085, 0.7192462 , 0.        , 0.68808943, 0.7366062 ,\n",
            "        0.        , 0.8008972 , 0.7603058 , 0.        , 0.        ,\n",
            "        0.9732673 , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.58595043, 0.        ,\n",
            "        0.        , 0.        , 0.7249135 , 0.582682  , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.6333177 , 0.        , 0.        , 0.        ,\n",
            "        0.84702843, 0.47669074, 0.        , 0.        , 0.6752565 ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.770561  , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.81485474, 0.        , 0.64058065, 0.78174216,\n",
            "        0.        , 0.        , 0.7617461 , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.82755107, 0.        , 0.        ,\n",
            "        0.80568486, 0.        , 0.        , 0.        , 0.8575809 ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.7267382 ,\n",
            "        0.6099159 , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.45891792, 0.        ,\n",
            "        0.        , 0.5996203 , 0.        , 0.7961348 , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.8309772 , 0.        ,\n",
            "        0.        , 0.        , 0.5637293 , 0.72889966, 0.77433836,\n",
            "        0.        , 0.        , 0.04498467, 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.43078363, 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.7167383 , 0.7678255 ,\n",
            "        0.        , 0.10020256, 0.7984608 , 0.        , 0.        ]],\n",
            "      dtype=float32)], [array([[0.9999999]], dtype=float32)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlfPfoYbHx2x",
        "colab_type": "text"
      },
      "source": [
        "### Predicting the review's sentiment for test sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrBHy62jcgVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INDEX_FROM=3 \n",
        "word_to_id = imdb.get_word_index()\n",
        "word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
        "word_to_id[\"<PAD>\"] = 0\n",
        "word_to_id[\"<START>\"] = 1\n",
        "word_to_id[\"<UNK>\"] = 2\n",
        "word_to_id[\"<UNUSED>\"] = 3\n",
        "\n",
        "id_to_word = {value:key for key,value in word_to_id.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QI0LuVr5GFg",
        "colab_type": "text"
      },
      "source": [
        "### Here I am taking two sample reviews from test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfLQfVlQMa44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user_review_1 = x_test[test_sample_1]\n",
        "user_review_2 = x_test[test_sample_2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNTU-TAhOlly",
        "colab_type": "code",
        "outputId": "78eda63d-0cc6-4d61-f3c0-388a739271f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "print('Actual label of first Review  : {}'.format(y_test[test_sample_1]))\n",
        "print('\\n==================================\\n')\n",
        "\n",
        "print(' '.join(id_to_word[id] for id in user_review_1 ))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual label of first Review  : 1\n",
            "\n",
            "==================================\n",
            "\n",
            "<START> this film was one that i have waited to see for some time i was glad to find it has been everything anticipated the writing of this film has been so finely crafted and <UNK> far beyond what is seen by the audience i found it amusing that so many people watching will not read between some very important lines but indeed if not the movie will make sense in a different way and is very brilliant the film has many stories and characters woven together around this one character <UNK> a man whom has rose from the streets amidst many <UNK> and become a very powerful criminal after spending some time in prison <UNK> finds a <UNK> in the justice system and through a disturbing turn of events is released only to find everything is not at all what it seems <UNK> finds himself going up against the higher realm of society and political <UNK> in order to make clear how important a man's word is and stands for a war begins as the street is in arms against <UNK> of wealth and corrupt power br br a build up to explosive and powerful non stop twists and turns this film will leave you <UNK> i found the cast of this movie to be outstanding and is not a movie to be ignored excellent go rent it today <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFu5Vh0yM3c5",
        "colab_type": "text"
      },
      "source": [
        "<b>Comment:</b> Above is the user review for a movie from test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbGpfAGyOotv",
        "colab_type": "code",
        "outputId": "9f3922e1-2ef8-4b49-ad30-20886022c6c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print('Actual label of second Review  : {}'.format(y_test[test_sample_2]))\n",
        "print('\\n==================================')\n",
        "print(' '.join(id_to_word[id] for id in user_review_2 ))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual label of second Review  : 0\n",
            "\n",
            "==================================\n",
            "<START> this film probably would have been good if they didn't use cgi computer generated imagery for the werewolf scenes it made the creatures look fake and the werewolves looked cartoonish cgi is great for certain effects like the in jurassic park or <UNK> but when we see a film where the creature must look completely real cgi is not the way to go look at an american werewolf in london no cgi just makeup and a mechanical creature and what you come up with was more realistic than what was shown in the sequel this film did offer a few gags that was fun to watch and the humor in this movie seemed to have drawn me in but it's nothing more than a film that i thought was o k and that's not good enough in my opinion an american werewolf in paris doesn't hold up to the original <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ozx69rPDNCNI",
        "colab_type": "text"
      },
      "source": [
        "<b>Comment:</b> Above is the user review for a movie from test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EQ7RMPg3S0Q",
        "colab_type": "code",
        "outputId": "686d6961-bc58-480c-a229-8cbd363cb1a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Texts \n",
        "texts = (user_review_1, user_review_2)\n",
        "padded_texts = pad_sequences(texts, maxlen=maxlen, value = 0.0)\n",
        "\n",
        "# Generating predictions\n",
        "predictions = model.predict(padded_texts)\n",
        "print(predictions[0])\n",
        "print(predictions[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.9999999]\n",
            "[0.00018888]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NG3ZnjzO5is",
        "colab_type": "text"
      },
      "source": [
        "###### Above we can see the probability of both the sample reviews which I have taken from test dataset. \n",
        "- My consideration:\n",
        "  - As I have used sigmoid activation funtion so if predicted probability of a review is greater than 0.5 which will be considered as 'possitive sentiment' or else review's sentiment will be classified as a 'negative sentiment'. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwYJl8IIMDLt",
        "colab_type": "text"
      },
      "source": [
        "#### Here defining a function to classify the sentiment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMCdiWugG3I_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_review(predict):\n",
        "    if predict == 0:\n",
        "      return 'Negative'\n",
        "    else :\n",
        "      return 'Postive'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ6RqAdeHTvU",
        "colab_type": "code",
        "outputId": "4aa6e3ca-a0fe-428c-a035-c777e6c20321",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        " print(\"User's sentiment for first sample review is  : \" + predict_review(int(round(predictions[0]))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User's sentiment for first sample review is  : Postive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib9RUYosG96x",
        "colab_type": "code",
        "outputId": "a877a841-9fc7-4d64-e46a-71f138f00933",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        " print(\"User's sentiment for second sample review is : \" + predict_review(int(round(predictions[1]))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User's sentiment for second sample review is : Negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avG8tQnoQY5i",
        "colab_type": "text"
      },
      "source": [
        "### Summary:\n",
        "- From the above test samples :\n",
        "- For the first review, the prediction is 0.9999999 which is close to 1, \"good\". This makes sense that the text clearly indicates that the viewer had positive sentiment about the movie. Also, some possitive words we can read in this review those are: 'glad', 'excellent', 'finely', 'outstanding'. \n",
        "- For the Second review, the prediction is 0.00018888 which is close to 0,  \"bad\". This makes sense that the text indicates that the viewer had a negative sentiment about the movie. Some negative words in this review are : 'not good', 'look fake', ''wasted.\n"
      ]
    }
  ]
}